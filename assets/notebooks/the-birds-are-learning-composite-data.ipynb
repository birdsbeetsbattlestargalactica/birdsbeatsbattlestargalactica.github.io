{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0486c10f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-06-06T02:45:58.643914Z",
     "iopub.status.busy": "2023-06-06T02:45:58.643570Z",
     "iopub.status.idle": "2023-06-06T04:22:40.843100Z",
     "shell.execute_reply": "2023-06-06T04:22:40.841944Z"
    },
    "papermill": {
     "duration": 5802.205338,
     "end_time": "2023-06-06T04:22:40.845499",
     "exception": false,
     "start_time": "2023-06-06T02:45:58.640161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/vision/zipball/v0.6.0\" to /root/.cache/torch/hub/v0.6.0.zip\n",
      "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
      "100%|██████████| 83.3M/83.3M [00:00<00:00, 228MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.001000\n",
      "[17,    10] loss: 0.772\n",
      "[17,    20] loss: 0.735\n",
      "[17,    30] loss: 0.826\n",
      "[17,    40] loss: 0.754\n",
      "[17,    50] loss: 0.674\n",
      "[17,    60] loss: 0.639\n",
      "[17,    70] loss: 0.685\n",
      "[17,    80] loss: 0.692\n",
      "[17,    90] loss: 0.687\n",
      "[17,   100] loss: 0.606\n",
      "[17,   110] loss: 0.678\n",
      "[17,   120] loss: 0.655\n",
      "[17,   130] loss: 0.666\n",
      "[17,   140] loss: 0.573\n",
      "[17,   150] loss: 0.625\n",
      "[17,   160] loss: 0.554\n",
      "[17,   170] loss: 0.709\n",
      "[17,   180] loss: 0.697\n",
      "[17,   190] loss: 0.560\n",
      "[17,   200] loss: 0.722\n",
      "[17,   210] loss: 0.673\n",
      "[17,   220] loss: 0.577\n",
      "[17,   230] loss: 0.589\n",
      "[17,   240] loss: 0.548\n",
      "[17,   250] loss: 0.604\n",
      "[17,   260] loss: 0.553\n",
      "[17,   270] loss: 0.533\n",
      "[17,   280] loss: 0.573\n",
      "[17,   290] loss: 0.551\n",
      "[17,   300] loss: 0.580\n",
      "[17,   310] loss: 0.529\n",
      "[17,   320] loss: 0.571\n",
      "[17,   330] loss: 0.618\n",
      "[17,   340] loss: 0.571\n",
      "[17,   350] loss: 0.578\n",
      "[17,   360] loss: 0.631\n",
      "[17,   370] loss: 0.534\n",
      "[17,   380] loss: 0.589\n",
      "[17,   390] loss: 0.491\n",
      "[17,   400] loss: 0.509\n",
      "[17,   410] loss: 0.547\n",
      "[17,   420] loss: 0.594\n",
      "[17,   430] loss: 0.550\n",
      "[17,   440] loss: 0.589\n",
      "[17,   450] loss: 0.531\n",
      "[17,   460] loss: 0.485\n",
      "[17,   470] loss: 0.620\n",
      "[17,   480] loss: 0.474\n",
      "[17,   490] loss: 0.551\n",
      "[17,   500] loss: 0.585\n",
      "[17,   510] loss: 0.489\n",
      "[17,   520] loss: 0.492\n",
      "[17,   530] loss: 0.469\n",
      "[17,   540] loss: 0.486\n",
      "[17,   550] loss: 0.527\n",
      "[17,   560] loss: 0.495\n",
      "[17,   570] loss: 0.581\n",
      "[17,   580] loss: 0.557\n",
      "[17,   590] loss: 0.532\n",
      "[17,   600] loss: 0.468\n",
      "[17,   610] loss: 0.509\n",
      "[17,   620] loss: 0.461\n",
      "[17,   630] loss: 0.476\n",
      "[17,   640] loss: 0.510\n",
      "[17,   650] loss: 0.436\n",
      "[17,   660] loss: 0.453\n",
      "[17,   670] loss: 0.416\n",
      "[17,   680] loss: 0.473\n",
      "[17,   690] loss: 0.551\n",
      "[17,   700] loss: 0.429\n",
      "[17,   710] loss: 0.439\n",
      "[17,   720] loss: 0.553\n",
      "[17,   730] loss: 0.418\n",
      "[17,   740] loss: 0.551\n",
      "[17,   750] loss: 0.455\n",
      "[17,   760] loss: 0.545\n",
      "[17,   770] loss: 0.518\n",
      "[17,   780] loss: 0.470\n",
      "[17,   790] loss: 0.466\n",
      "[17,   800] loss: 0.492\n",
      "[17,   810] loss: 0.553\n",
      "[17,   820] loss: 0.483\n",
      "[17,   830] loss: 0.448\n",
      "[17,   840] loss: 0.495\n",
      "[17,   850] loss: 0.468\n",
      "[17,   860] loss: 0.501\n",
      "[17,   870] loss: 0.478\n",
      "[17,   880] loss: 0.505\n",
      "[17,   890] loss: 0.453\n",
      "[17,   900] loss: 0.505\n",
      "[17,   910] loss: 0.455\n",
      "[17,   920] loss: 0.509\n",
      "[17,   930] loss: 0.501\n",
      "[17,   940] loss: 0.489\n",
      "[17,   950] loss: 0.480\n",
      "[17,   960] loss: 0.447\n",
      "[17,   970] loss: 0.470\n",
      "[17,   980] loss: 0.456\n",
      "[17,   990] loss: 0.494\n",
      "[17,  1000] loss: 0.473\n",
      "[17,  1010] loss: 0.450\n",
      "[17,  1020] loss: 0.422\n",
      "[17,  1030] loss: 0.410\n",
      "[17,  1040] loss: 0.468\n",
      "[17,  1050] loss: 0.446\n",
      "[17,  1060] loss: 0.439\n",
      "[17,  1070] loss: 0.438\n",
      "[17,  1080] loss: 0.451\n",
      "[17,  1090] loss: 0.472\n",
      "[17,  1100] loss: 0.517\n",
      "[17,  1110] loss: 0.513\n",
      "[17,  1120] loss: 0.412\n",
      "[17,  1130] loss: 0.434\n",
      "[17,  1140] loss: 0.479\n",
      "[17,  1150] loss: 0.433\n",
      "[17,  1160] loss: 0.381\n",
      "[17,  1170] loss: 0.435\n",
      "[17,  1180] loss: 0.387\n",
      "[17,  1190] loss: 0.486\n",
      "[17,  1200] loss: 0.457\n",
      "[17,  1210] loss: 0.469\n",
      "[17,  1220] loss: 0.475\n",
      "[17,  1230] loss: 0.412\n",
      "[17,  1240] loss: 0.432\n",
      "[17,  1250] loss: 0.445\n",
      "[17,  1260] loss: 0.451\n",
      "[17,  1270] loss: 0.485\n",
      "[17,  1280] loss: 0.409\n",
      "[17,  1290] loss: 0.431\n",
      "[17,  1300] loss: 0.462\n",
      "[17,  1310] loss: 0.450\n",
      "[17,  1320] loss: 0.401\n",
      "[17,  1330] loss: 0.442\n",
      "[17,  1340] loss: 0.379\n",
      "[17,  1350] loss: 0.403\n",
      "[17,  1360] loss: 0.428\n",
      "[17,  1370] loss: 0.439\n",
      "[17,  1380] loss: 0.383\n",
      "[17,  1390] loss: 0.432\n",
      "[17,  1400] loss: 0.438\n",
      "[17,  1410] loss: 0.473\n",
      "[17,  1420] loss: 0.481\n",
      "[17,  1430] loss: 0.477\n",
      "[17,  1440] loss: 0.446\n",
      "[17,  1450] loss: 0.440\n",
      "[17,  1460] loss: 0.466\n",
      "[17,  1470] loss: 0.502\n",
      "[17,  1480] loss: 0.419\n",
      "[17,  1490] loss: 0.390\n",
      "[17,  1500] loss: 0.389\n",
      "[17,  1510] loss: 0.425\n",
      "[17,  1520] loss: 0.409\n",
      "[17,  1530] loss: 0.474\n",
      "[17,  1540] loss: 0.469\n",
      "[17,  1550] loss: 0.418\n",
      "[17,  1560] loss: 0.418\n",
      "[17,  1570] loss: 0.445\n",
      "[17,  1580] loss: 0.466\n",
      "[17,  1590] loss: 0.403\n",
      "[17,  1600] loss: 0.465\n",
      "[17,  1610] loss: 0.481\n",
      "[17,  1620] loss: 0.389\n",
      "[17,  1630] loss: 0.451\n",
      "[17,  1640] loss: 0.426\n",
      "[17,  1650] loss: 0.466\n",
      "[17,  1660] loss: 0.410\n",
      "[17,  1670] loss: 0.435\n",
      "[17,  1680] loss: 0.441\n",
      "[17,  1690] loss: 0.420\n",
      "[17,  1700] loss: 0.490\n",
      "[17,  1710] loss: 0.443\n",
      "[17,  1720] loss: 0.426\n",
      "[17,  1730] loss: 0.364\n",
      "[17,  1740] loss: 0.408\n",
      "[17,  1750] loss: 0.422\n",
      "[17,  1760] loss: 0.330\n",
      "[17,  1770] loss: 0.523\n",
      "[17,  1780] loss: 0.442\n",
      "[17,  1790] loss: 0.421\n",
      "[17,  1800] loss: 0.483\n",
      "[17,  1810] loss: 0.439\n",
      "[17,  1820] loss: 0.506\n",
      "[17,  1830] loss: 0.464\n",
      "[17,  1840] loss: 0.354\n",
      "[17,  1850] loss: 0.438\n",
      "[17,  1860] loss: 0.384\n",
      "[17,  1870] loss: 0.410\n",
      "[17,  1880] loss: 0.400\n",
      "[17,  1890] loss: 0.426\n",
      "[17,  1900] loss: 0.394\n",
      "[17,  1910] loss: 0.407\n",
      "[17,  1920] loss: 0.431\n",
      "[17,  1930] loss: 0.472\n",
      "[17,  1940] loss: 0.433\n",
      "[17,  1950] loss: 0.455\n",
      "[17,  1960] loss: 0.432\n",
      "[17,  1970] loss: 0.396\n",
      "[17,  1980] loss: 0.423\n",
      "[17,  1990] loss: 0.351\n",
      "[17,  2000] loss: 0.471\n",
      "[17,  2010] loss: 0.454\n",
      "[17,  2020] loss: 0.423\n",
      "[17,  2030] loss: 0.417\n",
      "[17,  2040] loss: 0.411\n",
      "[17,  2050] loss: 0.420\n",
      "[17,  2060] loss: 0.403\n",
      "[17,  2070] loss: 0.380\n",
      "[17,  2080] loss: 0.457\n",
      "[17,  2090] loss: 0.441\n",
      "[17,  2100] loss: 0.449\n",
      "[17,  2110] loss: 0.399\n",
      "[17,  2120] loss: 0.432\n",
      "[17,  2130] loss: 0.307\n",
      "[17,  2140] loss: 0.433\n",
      "[17,  2150] loss: 0.396\n",
      "[17,  2160] loss: 0.430\n",
      "[17,  2170] loss: 0.479\n",
      "[17,  2180] loss: 0.415\n",
      "[17,  2190] loss: 0.433\n",
      "[17,  2200] loss: 0.417\n",
      "[17,  2210] loss: 0.416\n",
      "[17,  2220] loss: 0.407\n",
      "[17,  2230] loss: 0.368\n",
      "[17,  2240] loss: 0.372\n",
      "[17,  2250] loss: 0.425\n",
      "[17,  2260] loss: 0.413\n",
      "[17,  2270] loss: 0.391\n",
      "[17,  2280] loss: 0.419\n",
      "[17,  2290] loss: 0.543\n",
      "[17,  2300] loss: 0.369\n",
      "[17,  2310] loss: 0.401\n",
      "[17,  2320] loss: 0.443\n",
      "[17,  2330] loss: 0.392\n",
      "[17,  2340] loss: 0.407\n",
      "[17,  2350] loss: 0.392\n",
      "[17,  2360] loss: 0.419\n",
      "[17,  2370] loss: 0.419\n",
      "[17,  2380] loss: 0.384\n",
      "[17,  2390] loss: 0.393\n",
      "[17,  2400] loss: 0.389\n",
      "[17,  2410] loss: 0.394\n",
      "Learning rate: 0.001000\n",
      "[18,    10] loss: 0.337\n",
      "[18,    20] loss: 0.322\n",
      "[18,    30] loss: 0.279\n",
      "[18,    40] loss: 0.310\n",
      "[18,    50] loss: 0.326\n",
      "[18,    60] loss: 0.287\n",
      "[18,    70] loss: 0.297\n",
      "[18,    80] loss: 0.278\n",
      "[18,    90] loss: 0.351\n",
      "[18,   100] loss: 0.318\n",
      "[18,   110] loss: 0.319\n",
      "[18,   120] loss: 0.326\n",
      "[18,   130] loss: 0.297\n",
      "[18,   140] loss: 0.316\n",
      "[18,   150] loss: 0.298\n",
      "[18,   160] loss: 0.301\n",
      "[18,   170] loss: 0.356\n",
      "[18,   180] loss: 0.293\n",
      "[18,   190] loss: 0.309\n",
      "[18,   200] loss: 0.267\n",
      "[18,   210] loss: 0.293\n",
      "[18,   220] loss: 0.324\n",
      "[18,   230] loss: 0.297\n",
      "[18,   240] loss: 0.282\n",
      "[18,   250] loss: 0.338\n",
      "[18,   260] loss: 0.349\n",
      "[18,   270] loss: 0.309\n",
      "[18,   280] loss: 0.324\n",
      "[18,   290] loss: 0.287\n",
      "[18,   300] loss: 0.291\n",
      "[18,   310] loss: 0.341\n",
      "[18,   320] loss: 0.400\n",
      "[18,   330] loss: 0.269\n",
      "[18,   340] loss: 0.289\n",
      "[18,   350] loss: 0.341\n",
      "[18,   360] loss: 0.299\n",
      "[18,   370] loss: 0.303\n",
      "[18,   380] loss: 0.313\n",
      "[18,   390] loss: 0.266\n",
      "[18,   400] loss: 0.273\n",
      "[18,   410] loss: 0.319\n",
      "[18,   420] loss: 0.295\n",
      "[18,   430] loss: 0.318\n",
      "[18,   440] loss: 0.305\n",
      "[18,   450] loss: 0.288\n",
      "[18,   460] loss: 0.305\n",
      "[18,   470] loss: 0.313\n",
      "[18,   480] loss: 0.320\n",
      "[18,   490] loss: 0.272\n",
      "[18,   500] loss: 0.321\n",
      "[18,   510] loss: 0.345\n",
      "[18,   520] loss: 0.274\n",
      "[18,   530] loss: 0.297\n",
      "[18,   540] loss: 0.355\n",
      "[18,   550] loss: 0.306\n",
      "[18,   560] loss: 0.317\n",
      "[18,   570] loss: 0.285\n",
      "[18,   580] loss: 0.317\n",
      "[18,   590] loss: 0.291\n",
      "[18,   600] loss: 0.350\n",
      "[18,   610] loss: 0.264\n",
      "[18,   620] loss: 0.324\n",
      "[18,   630] loss: 0.362\n",
      "[18,   640] loss: 0.283\n",
      "[18,   650] loss: 0.345\n",
      "[18,   660] loss: 0.315\n",
      "[18,   670] loss: 0.279\n",
      "[18,   680] loss: 0.320\n",
      "[18,   690] loss: 0.351\n",
      "[18,   700] loss: 0.354\n",
      "[18,   710] loss: 0.317\n",
      "[18,   720] loss: 0.278\n",
      "[18,   730] loss: 0.301\n",
      "[18,   740] loss: 0.308\n",
      "[18,   750] loss: 0.276\n",
      "[18,   760] loss: 0.325\n",
      "[18,   770] loss: 0.294\n",
      "[18,   780] loss: 0.345\n",
      "[18,   790] loss: 0.306\n",
      "[18,   800] loss: 0.275\n",
      "[18,   810] loss: 0.263\n",
      "[18,   820] loss: 0.346\n",
      "[18,   830] loss: 0.342\n",
      "[18,   840] loss: 0.338\n",
      "[18,   850] loss: 0.307\n",
      "[18,   860] loss: 0.278\n",
      "[18,   870] loss: 0.274\n",
      "[18,   880] loss: 0.286\n",
      "[18,   890] loss: 0.308\n",
      "[18,   900] loss: 0.353\n",
      "[18,   910] loss: 0.331\n",
      "[18,   920] loss: 0.331\n",
      "[18,   930] loss: 0.319\n",
      "[18,   940] loss: 0.351\n",
      "[18,   950] loss: 0.376\n",
      "[18,   960] loss: 0.280\n",
      "[18,   970] loss: 0.312\n",
      "[18,   980] loss: 0.303\n",
      "[18,   990] loss: 0.320\n",
      "[18,  1000] loss: 0.280\n",
      "[18,  1010] loss: 0.346\n",
      "[18,  1020] loss: 0.302\n",
      "[18,  1030] loss: 0.283\n",
      "[18,  1040] loss: 0.280\n",
      "[18,  1050] loss: 0.332\n",
      "[18,  1060] loss: 0.298\n",
      "[18,  1070] loss: 0.302\n",
      "[18,  1080] loss: 0.298\n",
      "[18,  1090] loss: 0.362\n",
      "[18,  1100] loss: 0.291\n",
      "[18,  1110] loss: 0.299\n",
      "[18,  1120] loss: 0.288\n",
      "[18,  1130] loss: 0.322\n",
      "[18,  1140] loss: 0.253\n",
      "[18,  1150] loss: 0.266\n",
      "[18,  1160] loss: 0.280\n",
      "[18,  1170] loss: 0.276\n",
      "[18,  1180] loss: 0.310\n",
      "[18,  1190] loss: 0.308\n",
      "[18,  1200] loss: 0.344\n",
      "[18,  1210] loss: 0.281\n",
      "[18,  1220] loss: 0.275\n",
      "[18,  1230] loss: 0.320\n",
      "[18,  1240] loss: 0.326\n",
      "[18,  1250] loss: 0.289\n",
      "[18,  1260] loss: 0.332\n",
      "[18,  1270] loss: 0.293\n",
      "[18,  1280] loss: 0.314\n",
      "[18,  1290] loss: 0.304\n",
      "[18,  1300] loss: 0.264\n",
      "[18,  1310] loss: 0.325\n",
      "[18,  1320] loss: 0.250\n",
      "[18,  1330] loss: 0.333\n",
      "[18,  1340] loss: 0.286\n",
      "[18,  1350] loss: 0.275\n",
      "[18,  1360] loss: 0.287\n",
      "[18,  1370] loss: 0.353\n",
      "[18,  1380] loss: 0.309\n",
      "[18,  1390] loss: 0.253\n",
      "[18,  1400] loss: 0.279\n",
      "[18,  1410] loss: 0.259\n",
      "[18,  1420] loss: 0.283\n",
      "[18,  1430] loss: 0.297\n",
      "[18,  1440] loss: 0.327\n",
      "[18,  1450] loss: 0.299\n",
      "[18,  1460] loss: 0.270\n",
      "[18,  1470] loss: 0.309\n",
      "[18,  1480] loss: 0.263\n",
      "[18,  1490] loss: 0.321\n",
      "[18,  1500] loss: 0.269\n",
      "[18,  1510] loss: 0.302\n",
      "[18,  1520] loss: 0.324\n",
      "[18,  1530] loss: 0.352\n",
      "[18,  1540] loss: 0.310\n",
      "[18,  1550] loss: 0.294\n",
      "[18,  1560] loss: 0.337\n",
      "[18,  1570] loss: 0.299\n",
      "[18,  1580] loss: 0.285\n",
      "[18,  1590] loss: 0.288\n",
      "[18,  1600] loss: 0.292\n",
      "[18,  1610] loss: 0.322\n",
      "[18,  1620] loss: 0.285\n",
      "[18,  1630] loss: 0.365\n",
      "[18,  1640] loss: 0.307\n",
      "[18,  1650] loss: 0.266\n",
      "[18,  1660] loss: 0.296\n",
      "[18,  1670] loss: 0.331\n",
      "[18,  1680] loss: 0.364\n",
      "[18,  1690] loss: 0.310\n",
      "[18,  1700] loss: 0.311\n",
      "[18,  1710] loss: 0.302\n",
      "[18,  1720] loss: 0.312\n",
      "[18,  1730] loss: 0.295\n",
      "[18,  1740] loss: 0.308\n",
      "[18,  1750] loss: 0.252\n",
      "[18,  1760] loss: 0.296\n",
      "[18,  1770] loss: 0.280\n",
      "[18,  1780] loss: 0.337\n",
      "[18,  1790] loss: 0.288\n",
      "[18,  1800] loss: 0.277\n",
      "[18,  1810] loss: 0.283\n",
      "[18,  1820] loss: 0.309\n",
      "[18,  1830] loss: 0.243\n",
      "[18,  1840] loss: 0.342\n",
      "[18,  1850] loss: 0.311\n",
      "[18,  1860] loss: 0.306\n",
      "[18,  1870] loss: 0.277\n",
      "[18,  1880] loss: 0.339\n",
      "[18,  1890] loss: 0.261\n",
      "[18,  1900] loss: 0.296\n",
      "[18,  1910] loss: 0.271\n",
      "[18,  1920] loss: 0.285\n",
      "[18,  1930] loss: 0.300\n",
      "[18,  1940] loss: 0.289\n",
      "[18,  1950] loss: 0.321\n",
      "[18,  1960] loss: 0.286\n",
      "[18,  1970] loss: 0.263\n",
      "[18,  1980] loss: 0.262\n",
      "[18,  1990] loss: 0.300\n",
      "[18,  2000] loss: 0.259\n",
      "[18,  2010] loss: 0.333\n",
      "[18,  2020] loss: 0.275\n",
      "[18,  2030] loss: 0.353\n",
      "[18,  2040] loss: 0.304\n",
      "[18,  2050] loss: 0.304\n",
      "[18,  2060] loss: 0.291\n",
      "[18,  2070] loss: 0.300\n",
      "[18,  2080] loss: 0.302\n",
      "[18,  2090] loss: 0.274\n",
      "[18,  2100] loss: 0.335\n",
      "[18,  2110] loss: 0.273\n",
      "[18,  2120] loss: 0.299\n",
      "[18,  2130] loss: 0.273\n",
      "[18,  2140] loss: 0.328\n",
      "[18,  2150] loss: 0.326\n",
      "[18,  2160] loss: 0.259\n",
      "[18,  2170] loss: 0.292\n",
      "[18,  2180] loss: 0.299\n",
      "[18,  2190] loss: 0.288\n",
      "[18,  2200] loss: 0.301\n",
      "[18,  2210] loss: 0.292\n",
      "[18,  2220] loss: 0.288\n",
      "[18,  2230] loss: 0.279\n",
      "[18,  2240] loss: 0.327\n",
      "[18,  2250] loss: 0.254\n",
      "[18,  2260] loss: 0.294\n",
      "[18,  2270] loss: 0.291\n",
      "[18,  2280] loss: 0.287\n",
      "[18,  2290] loss: 0.284\n",
      "[18,  2300] loss: 0.313\n",
      "[18,  2310] loss: 0.288\n",
      "[18,  2320] loss: 0.297\n",
      "[18,  2330] loss: 0.278\n",
      "[18,  2340] loss: 0.292\n",
      "[18,  2350] loss: 0.280\n",
      "[18,  2360] loss: 0.329\n",
      "[18,  2370] loss: 0.250\n",
      "[18,  2380] loss: 0.264\n",
      "[18,  2390] loss: 0.298\n",
      "[18,  2400] loss: 0.296\n",
      "[18,  2410] loss: 0.346\n",
      "Learning rate: 0.001000\n",
      "[19,    10] loss: 0.243\n",
      "[19,    20] loss: 0.262\n",
      "[19,    30] loss: 0.274\n",
      "[19,    40] loss: 0.233\n",
      "[19,    50] loss: 0.234\n",
      "[19,    60] loss: 0.232\n",
      "[19,    70] loss: 0.214\n",
      "[19,    80] loss: 0.202\n",
      "[19,    90] loss: 0.203\n",
      "[19,   100] loss: 0.251\n",
      "[19,   110] loss: 0.200\n",
      "[19,   120] loss: 0.230\n",
      "[19,   130] loss: 0.244\n",
      "[19,   140] loss: 0.238\n",
      "[19,   150] loss: 0.219\n",
      "[19,   160] loss: 0.230\n",
      "[19,   170] loss: 0.209\n",
      "[19,   180] loss: 0.250\n",
      "[19,   190] loss: 0.259\n",
      "[19,   200] loss: 0.242\n",
      "[19,   210] loss: 0.204\n",
      "[19,   220] loss: 0.241\n",
      "[19,   230] loss: 0.229\n",
      "[19,   240] loss: 0.208\n",
      "[19,   250] loss: 0.206\n",
      "[19,   260] loss: 0.220\n",
      "[19,   270] loss: 0.259\n",
      "[19,   280] loss: 0.235\n",
      "[19,   290] loss: 0.208\n",
      "[19,   300] loss: 0.252\n",
      "[19,   310] loss: 0.255\n",
      "[19,   320] loss: 0.222\n",
      "[19,   330] loss: 0.229\n",
      "[19,   340] loss: 0.258\n",
      "[19,   350] loss: 0.194\n",
      "[19,   360] loss: 0.252\n",
      "[19,   370] loss: 0.206\n",
      "[19,   380] loss: 0.229\n",
      "[19,   390] loss: 0.201\n",
      "[19,   400] loss: 0.266\n",
      "[19,   410] loss: 0.214\n",
      "[19,   420] loss: 0.230\n",
      "[19,   430] loss: 0.236\n",
      "[19,   440] loss: 0.239\n",
      "[19,   450] loss: 0.250\n",
      "[19,   460] loss: 0.273\n",
      "[19,   470] loss: 0.219\n",
      "[19,   480] loss: 0.189\n",
      "[19,   490] loss: 0.245\n",
      "[19,   500] loss: 0.210\n",
      "[19,   510] loss: 0.211\n",
      "[19,   520] loss: 0.188\n",
      "[19,   530] loss: 0.231\n",
      "[19,   540] loss: 0.190\n",
      "[19,   550] loss: 0.231\n",
      "[19,   560] loss: 0.218\n",
      "[19,   570] loss: 0.225\n",
      "[19,   580] loss: 0.237\n",
      "[19,   590] loss: 0.198\n",
      "[19,   600] loss: 0.206\n",
      "[19,   610] loss: 0.222\n",
      "[19,   620] loss: 0.254\n",
      "[19,   630] loss: 0.244\n",
      "[19,   640] loss: 0.265\n",
      "[19,   650] loss: 0.271\n",
      "[19,   660] loss: 0.236\n",
      "[19,   670] loss: 0.216\n",
      "[19,   680] loss: 0.237\n",
      "[19,   690] loss: 0.280\n",
      "[19,   700] loss: 0.242\n",
      "[19,   710] loss: 0.230\n",
      "[19,   720] loss: 0.245\n",
      "[19,   730] loss: 0.219\n",
      "[19,   740] loss: 0.236\n",
      "[19,   750] loss: 0.255\n",
      "[19,   760] loss: 0.267\n",
      "[19,   770] loss: 0.246\n",
      "[19,   780] loss: 0.187\n",
      "[19,   790] loss: 0.272\n",
      "[19,   800] loss: 0.248\n",
      "[19,   810] loss: 0.258\n",
      "[19,   820] loss: 0.194\n",
      "[19,   830] loss: 0.221\n",
      "[19,   840] loss: 0.223\n",
      "[19,   850] loss: 0.233\n",
      "[19,   860] loss: 0.211\n",
      "[19,   870] loss: 0.227\n",
      "[19,   880] loss: 0.214\n",
      "[19,   890] loss: 0.246\n",
      "[19,   900] loss: 0.238\n",
      "[19,   910] loss: 0.226\n",
      "[19,   920] loss: 0.203\n",
      "[19,   930] loss: 0.255\n",
      "[19,   940] loss: 0.275\n",
      "[19,   950] loss: 0.188\n",
      "[19,   960] loss: 0.251\n",
      "[19,   970] loss: 0.225\n",
      "[19,   980] loss: 0.254\n",
      "[19,   990] loss: 0.233\n",
      "[19,  1000] loss: 0.185\n",
      "[19,  1010] loss: 0.218\n",
      "[19,  1020] loss: 0.241\n",
      "[19,  1030] loss: 0.230\n",
      "[19,  1040] loss: 0.246\n",
      "[19,  1050] loss: 0.234\n",
      "[19,  1060] loss: 0.206\n",
      "[19,  1070] loss: 0.228\n",
      "[19,  1080] loss: 0.237\n",
      "[19,  1090] loss: 0.267\n",
      "[19,  1100] loss: 0.247\n",
      "[19,  1110] loss: 0.266\n",
      "[19,  1120] loss: 0.252\n",
      "[19,  1130] loss: 0.220\n",
      "[19,  1140] loss: 0.198\n",
      "[19,  1150] loss: 0.204\n",
      "[19,  1160] loss: 0.273\n",
      "[19,  1170] loss: 0.226\n",
      "[19,  1180] loss: 0.264\n",
      "[19,  1190] loss: 0.253\n",
      "[19,  1200] loss: 0.244\n",
      "[19,  1210] loss: 0.243\n",
      "[19,  1220] loss: 0.226\n",
      "[19,  1230] loss: 0.239\n",
      "[19,  1240] loss: 0.271\n",
      "[19,  1250] loss: 0.207\n",
      "[19,  1260] loss: 0.211\n",
      "[19,  1270] loss: 0.218\n",
      "[19,  1280] loss: 0.226\n",
      "[19,  1290] loss: 0.258\n",
      "[19,  1300] loss: 0.237\n",
      "[19,  1310] loss: 0.205\n",
      "[19,  1320] loss: 0.229\n",
      "[19,  1330] loss: 0.236\n",
      "[19,  1340] loss: 0.195\n",
      "[19,  1350] loss: 0.258\n",
      "[19,  1360] loss: 0.231\n",
      "[19,  1370] loss: 0.227\n",
      "[19,  1380] loss: 0.226\n",
      "[19,  1390] loss: 0.263\n",
      "[19,  1400] loss: 0.250\n",
      "[19,  1410] loss: 0.241\n",
      "[19,  1420] loss: 0.220\n",
      "[19,  1430] loss: 0.227\n",
      "[19,  1440] loss: 0.206\n",
      "[19,  1450] loss: 0.245\n",
      "[19,  1460] loss: 0.237\n",
      "[19,  1470] loss: 0.218\n",
      "[19,  1480] loss: 0.213\n",
      "[19,  1490] loss: 0.234\n",
      "[19,  1500] loss: 0.238\n",
      "[19,  1510] loss: 0.227\n",
      "[19,  1520] loss: 0.266\n",
      "[19,  1530] loss: 0.270\n",
      "[19,  1540] loss: 0.204\n",
      "[19,  1550] loss: 0.216\n",
      "[19,  1560] loss: 0.245\n",
      "[19,  1570] loss: 0.233\n",
      "[19,  1580] loss: 0.219\n",
      "[19,  1590] loss: 0.215\n",
      "[19,  1600] loss: 0.215\n",
      "[19,  1610] loss: 0.232\n",
      "[19,  1620] loss: 0.232\n",
      "[19,  1630] loss: 0.234\n",
      "[19,  1640] loss: 0.235\n",
      "[19,  1650] loss: 0.225\n",
      "[19,  1660] loss: 0.223\n",
      "[19,  1670] loss: 0.256\n",
      "[19,  1680] loss: 0.231\n",
      "[19,  1690] loss: 0.240\n",
      "[19,  1700] loss: 0.235\n",
      "[19,  1710] loss: 0.235\n",
      "[19,  1720] loss: 0.246\n",
      "[19,  1730] loss: 0.193\n",
      "[19,  1740] loss: 0.242\n",
      "[19,  1750] loss: 0.220\n",
      "[19,  1760] loss: 0.210\n",
      "[19,  1770] loss: 0.230\n",
      "[19,  1780] loss: 0.207\n",
      "[19,  1790] loss: 0.218\n",
      "[19,  1800] loss: 0.239\n",
      "[19,  1810] loss: 0.219\n",
      "[19,  1820] loss: 0.215\n",
      "[19,  1830] loss: 0.203\n",
      "[19,  1840] loss: 0.264\n",
      "[19,  1850] loss: 0.228\n",
      "[19,  1860] loss: 0.220\n",
      "[19,  1870] loss: 0.198\n",
      "[19,  1880] loss: 0.214\n",
      "[19,  1890] loss: 0.195\n",
      "[19,  1900] loss: 0.198\n",
      "[19,  1910] loss: 0.229\n",
      "[19,  1920] loss: 0.243\n",
      "[19,  1930] loss: 0.218\n",
      "[19,  1940] loss: 0.246\n",
      "[19,  1950] loss: 0.238\n",
      "[19,  1960] loss: 0.207\n",
      "[19,  1970] loss: 0.237\n",
      "[19,  1980] loss: 0.229\n",
      "[19,  1990] loss: 0.244\n",
      "[19,  2000] loss: 0.250\n",
      "[19,  2010] loss: 0.232\n",
      "[19,  2020] loss: 0.189\n",
      "[19,  2030] loss: 0.185\n",
      "[19,  2040] loss: 0.226\n",
      "[19,  2050] loss: 0.221\n",
      "[19,  2060] loss: 0.254\n",
      "[19,  2070] loss: 0.208\n",
      "[19,  2080] loss: 0.241\n",
      "[19,  2090] loss: 0.222\n",
      "[19,  2100] loss: 0.220\n",
      "[19,  2110] loss: 0.228\n",
      "[19,  2120] loss: 0.248\n",
      "[19,  2130] loss: 0.201\n",
      "[19,  2140] loss: 0.268\n",
      "[19,  2150] loss: 0.254\n",
      "[19,  2160] loss: 0.176\n",
      "[19,  2170] loss: 0.264\n",
      "[19,  2180] loss: 0.243\n",
      "[19,  2190] loss: 0.218\n",
      "[19,  2200] loss: 0.238\n",
      "[19,  2210] loss: 0.221\n",
      "[19,  2220] loss: 0.261\n",
      "[19,  2230] loss: 0.212\n",
      "[19,  2240] loss: 0.222\n",
      "[19,  2250] loss: 0.254\n",
      "[19,  2260] loss: 0.245\n",
      "[19,  2270] loss: 0.197\n",
      "[19,  2280] loss: 0.230\n",
      "[19,  2290] loss: 0.250\n",
      "[19,  2300] loss: 0.231\n",
      "[19,  2310] loss: 0.222\n",
      "[19,  2320] loss: 0.225\n",
      "[19,  2330] loss: 0.237\n",
      "[19,  2340] loss: 0.226\n",
      "[19,  2350] loss: 0.237\n",
      "[19,  2360] loss: 0.224\n",
      "[19,  2370] loss: 0.232\n",
      "[19,  2380] loss: 0.228\n",
      "[19,  2390] loss: 0.206\n",
      "[19,  2400] loss: 0.250\n",
      "[19,  2410] loss: 0.223\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import itertools\n",
    "from torchvision.models import resnet34, ResNet34_Weights\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "### set up directories\n",
    "prev_cpts = '/kaggle/input/restartdata/'\n",
    "checkpoints = '/kaggle/working/'\n",
    "\n",
    "def smooth(x, size):\n",
    "  return np.convolve(x, np.ones(size)/size, mode='valid')\n",
    "\n",
    "def create_transforms(input_size=128, horizontal_flip_prob=0, vertical_flip_prob=0, color_jitter_prob=0, \\\n",
    "                      brightness_prob=0, contrast_prob=0, saturation_prob=0, hue_prob=0):\n",
    "    transform_list = [\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.RandomCrop(input_size, padding=8, padding_mode='edge'),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    "    \n",
    "    if horizontal_flip_prob > 0:\n",
    "        transform_list.append(transforms.RandomHorizontalFlip(p=horizontal_flip_prob))\n",
    "    \n",
    "    if vertical_flip_prob > 0:\n",
    "        transform_list.append(transforms.RandomVerticalFlip(p=vertical_flip_prob))\n",
    "    \n",
    "    if (brightness_prob + contrast_prob + saturation_prob + hue_prob) > 0:\n",
    "        transform_list.append(transforms.ColorJitter(brightness=brightness_prob, contrast=contrast_prob,\n",
    "                                                     saturation=saturation_prob, hue=hue_prob))\n",
    "    \n",
    "    return transforms.Compose(transform_list)\n",
    "\n",
    "def get_bird_data(augmentation=0, input_size=128):\n",
    "    transform_original = create_transforms(input_size=input_size)\n",
    "    transform_hor = create_transforms(input_size=input_size, horizontal_flip_prob=1)\n",
    "    transform_ver = create_transforms(input_size=input_size, vertical_flip_prob=1)\n",
    "    transform_jitter = create_transforms(input_size=input_size, saturation_prob=0.5)\n",
    "    \n",
    "    \n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "    \n",
    "\n",
    "    data_path = '/kaggle/input/birds23sp/birds/'\n",
    "\n",
    "    trainset = torch.utils.data.ConcatDataset( [\n",
    "                    torchvision.datasets.ImageFolder(root=data_path + 'train', transform=transform_original), \\\n",
    "                    torchvision.datasets.ImageFolder(root=data_path + 'train', transform=transform_hor), \\\n",
    "                    torchvision.datasets.ImageFolder(root=data_path + 'train', transform=transform_ver), \\\n",
    "                    torchvision.datasets.ImageFolder(root=data_path + 'train', transform=transform_jitter)\n",
    "                ])\n",
    "    \n",
    "    testset = torchvision.datasets.ImageFolder(root=data_path + 'test', transform=transform_test)\n",
    "    \n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False, num_workers=2)\n",
    "    \n",
    "    \n",
    "    classes = open(data_path + \"names.txt\").read().strip().split(\"\\n\")\n",
    "    class_to_idx = trainset.datasets[0].class_to_idx\n",
    "    idx_to_class = {int(v): int(k) for k, v in class_to_idx.items()}\n",
    "    idx_to_name = {k: classes[v] for k,v in idx_to_class.items()}\n",
    "    return {'train': trainloader, 'test': testloader, 'to_class': idx_to_class, 'to_name':idx_to_name}\n",
    "\n",
    "def train(net, dataloader, epochs=1, start_epoch=0, lr=0.01, momentum=0.90, decay=0.0005, \n",
    "          verbose=1, print_every=10, state=None, checkpoint_path=None):\n",
    "    net.to(device)\n",
    "    net.train()\n",
    "    losses = []\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum, weight_decay=decay)\n",
    "    #optimizer = optim.RMSprop(net.parameters(), lr=lr, momentum=momentum, weight_decay=decay)\n",
    "    #adam\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=2, threshold=0.0001, threshold_mode='abs')\n",
    "\n",
    "    # Load previous training state\n",
    "    if state:\n",
    "        net.load_state_dict(state['net'])\n",
    "        optimizer.load_state_dict(state['optimizer'])\n",
    "        start_epoch = state['epoch']\n",
    "        losses = state['losses']\n",
    "\n",
    "    # Fast forward lr schedule through already trained epochs\n",
    "#     for epoch in range(start_epoch):\n",
    "#         if epoch in schedule:\n",
    "#             print (\"Learning rate: %f\"% schedule[epoch])\n",
    "#             for g in optimizer.param_groups:\n",
    "#                 g['lr'] = schedule[epoch]\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        sum_loss = 0.0\n",
    "        \n",
    "        for g in optimizer.param_groups:\n",
    "                print (\"Learning rate: %f\"% g['lr'])\n",
    "\n",
    "        # Update learning rate when scheduled\n",
    "#         if epoch in schedule:\n",
    "#             print (\"Learning rate: %f\"% schedule[epoch])\n",
    "#             for g in optimizer.param_groups:\n",
    "#                 g['lr'] = schedule[epoch]\n",
    "\n",
    "        for i, batch in enumerate(dataloader, 0):\n",
    "            inputs, labels = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()  # autograd magic, computes all the partial derivatives\n",
    "            optimizer.step() # takes a step in gradient direction\n",
    "            \n",
    "\n",
    "            losses.append(loss.item())\n",
    "            sum_loss += loss.item()\n",
    "\n",
    "            if i % print_every == print_every-1:    # print every 10 mini-batches\n",
    "                if verbose:\n",
    "                  print('[%d, %5d] loss: %.3f' % (epoch, i + 1, sum_loss / print_every))\n",
    "                sum_loss = 0.0\n",
    "        scheduler.step(sum_loss)\n",
    "        if checkpoint_path:\n",
    "            state = {'epoch': epoch+1, 'net': net.state_dict(), 'optimizer': optimizer.state_dict(), 'losses': losses}\n",
    "            torch.save(state, checkpoint_path + 'retrain-checkpoint-%d.pkl'%(epoch+1))\n",
    "            plt.plot(smooth(state['losses'], 50))\n",
    "            plt.savefig('checkpoint-%d.png'%(epoch+1))\n",
    "    return losses\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "data = get_bird_data(input_size=256)\n",
    "resnet = torch.hub.load('pytorch/vision:v0.6.0', 'resnet34', weights=ResNet34_Weights.IMAGENET1K_V1)\n",
    "resnet.fc = nn.Linear(512, 555)\n",
    "\n",
    "# selectable between starting at a checkpoint or from scratch.\n",
    "if (1):\n",
    "    state = torch.load(prev_cpts + 'plateau_checkpoint-17.pkl')\n",
    "    resnet.load_state_dict(state['net'])\n",
    "    losses = train(resnet, data['train'], epochs=20, lr=.01, print_every=10, checkpoint_path=checkpoints, state=state)\n",
    "else: \n",
    "    losses = train(resnet, data['train'], epochs=25, lr=.01, print_every=10, checkpoint_path=checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31869ab6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-06T04:22:40.955755Z",
     "iopub.status.busy": "2023-06-06T04:22:40.954830Z",
     "iopub.status.idle": "2023-06-06T04:22:40.964556Z",
     "shell.execute_reply": "2023-06-06T04:22:40.963569Z"
    },
    "papermill": {
     "duration": 0.066653,
     "end_time": "2023-06-06T04:22:40.966935",
     "exception": false,
     "start_time": "2023-06-06T04:22:40.900282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def predict(net, dataloader, ofname):\n",
    "    out = open(ofname, 'w')\n",
    "    out.write(\"path,class\\n\")\n",
    "    net.to(device)\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(dataloader, 0):\n",
    "            if i%100 == 0:\n",
    "                print(i)\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            fname, _ = dataloader.dataset.samples[i]\n",
    "            out.write(\"test/{},{}\\n\".format(fname.split('/')[-1], data['to_class'][predicted.item()]))\n",
    "    out.close()\n",
    "\n",
    "\n",
    "if (0):\n",
    "    state = torch.load('/kaggle/input/restartdata/resnet50-checkpoint-15.pkl')\n",
    "    resnet.load_state_dict(state['net'])\n",
    "    predict(resnet, data['test'], checkpoints + \"preds_res50.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5816.676824,
   "end_time": "2023-06-06T04:22:44.247101",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-06-06T02:45:47.570277",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
